# This docker-compose file is intended for running Hay say on a server for others to use.

services:

  nginx:
    depends_on:
      - hay_say_ui
      # - synthapp
    image: hydrusbeta/nginx:synthapp
    user: root
    ports:
      - 80:80
      - 443:443
#    volumes:
#      - type: bind
#        source: /etc/pki/tls/certs
#        target: /etc/pki/tls/certs
#      - type: bind
#        source: /etc/pki/tls/private
#        target: /etc/pki/tls/private
    command: ["/bin/sh", "-c", "
               printf \"server_tokens off;\\n
                 access_log /var/log/nginx/synthapp.access.log;\\n
                 error_log /var/log/nginx/synthapp.error.log;\\n
                 limit_req_zone \\$$binary_remote_addr zone=mylimit:10m rate=2r/s;\\n
                 client_max_body_size 100M;\\n
                 \\n
                 # server {\\n
                 #    listen 80;\\n
                 #    server_name _;\\n
                 #    return 301 https://\\$$host\\$$request_uri;\\n
                 # }\\n
                 \\n
                 server {\\n
                    listen 80 default_server;\\n
                    server_name _;\\n
                    location / {\\n
                       limit_req zone=mylimit burst=500 nodelay;\\n
                       proxy_pass http://hay_say_ui:6573;\\n
                       proxy_set_header Host \\$$host;\\n
                       proxy_set_header Cookie \\$$http_cookie;\\n
                    }\\n
                 }\\n
                 # \\n
                 # server {\\n
                 #    listen 80;\\n
                 #    server_name .synthapp.*;\\n
                 #    location / {\\n
                 #       limit_req zone=mylimit burst=50 nodelay;\\n
                 #       proxy_pass http://synthapp:3334;\\n
                 #       proxy_set_header Host \\$$host;\\n
                 #    }\\n
                 #    location /static {\\n
                 #       limit_req zone=mylimit burst=50 nodelay;\\n
                 #       autoindex on;\\n
                 #       alias /home/luna/synthapp/website/ponyonline/static;\\n
                 #    }\\n
                 # }\\n\" 
               > /etc/nginx/conf.d/synthapp.conf && 
               nginx -g 'daemon off;'"]

#  synthapp:
#    image: hydrusbeta/synthapp
#    volumes:
#      - synthapp_models:/home/luna/synthapp/models
#    working_dir: /home/luna/synthapp
#    # run_linux only starts the rpyc ThreadedServer, due to modifications that were made to webapplauncher.py in
#    # the Dockerfile. This lets us start the main application in gunicorn.
#    command: ["/bin/sh", "-c", "
#               sed -i \"s/ALLOWED_HOSTS = \\['127.0.0.1', 'localhost'\\]/ALLOWED_HOSTS = ['.synthapp.*']/\" website/ponyonline/ponyonline/settings.py &&
#               echo \"sed -i '22i \\ \\ \\ \\ -->' ./website/ponyonline/templates/ttsapp.html\" &&
#               echo \"sed -i '19i \\ \\ \\ \\ <!--' ./website/ponyonline/templates/ttsapp.html\" &&
#               echo \"sed -i '93s/@never_cache/#@never_cache/' ./website/ponyonline/tts/views.py\" &&
#               echo \"sed -i '23s/path/#path/' ./website/ponyonline/ponyonline/urls.py\" &&
#               echo \"sed -i '28,30s/path/#path/' ./website/ponyonline/ponyonline/urls.py\" &&
#               ./run_linux &
#               ./bin/micromamba-linux-64 run -n synthapp1
#                  --root-prefix /home/luna/micromamba/ gunicorn
#                  --workers 6
#                  --bind 0.0.0.0:3334
#                  --chdir ./website/ponyonline/
#                  ponyonline.wsgi:application"]


  # The Redis container provides an in-memory data store that can be shared between applications.
  # This allows plotly to pass data to background workers.
  redis:
    image: redis
    command: redis-server
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      start_period: 15s
      start_interval: 1s
      # start_interval is not available in versions of Docker Engine earlier than 25. For backwards
      # compatibility, set the interval property for now. Remove the line below sometime in the future,
      # once everyone is on version 25+.
      interval: 1s

  # This container runs the main UI
  hay_say_ui:
    depends_on:
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:hay_say_ui
    working_dir: /home/luna/hay_say/hay_say_ui
    volumes:
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    # Override the CMD in the Docker file to enable model management, update model lists on startup, and automatically
    # migrate all models to the models folder. Also spin up 3 instances of celery (one for generating with CPU, one for
    # generating with GPU and one for downloading models), with 5 workers for downloading models and a single worker
    # each for generating output with GPU and CPU.
    command: ["/bin/sh", "-c", "
              celery --workdir ~/hay_say/hay_say_ui/ -A celery_download:celery_app worker --loglevel=INFO --concurrency 5 --include_architecture ControllableTalkNet --include_architecture SoVitsSvc3 --include_architecture SoVitsSvc4 --include_architecture SoVitsSvc5 --include_architecture Rvc --include_architecture StyleTTS2 & 
              celery --workdir ~/hay_say/hay_say_ui/ -A celery_generate_gpu:celery_app worker --loglevel=INFO --concurrency 1 --cache_implementation file --include_architecture ControllableTalkNet --include_architecture SoVitsSvc3 --include_architecture SoVitsSvc4 --include_architecture SoVitsSvc5 --include_architecture Rvc --include_architecture StyleTTS2 &
              celery --workdir ~/hay_say/hay_say_ui/ -A celery_generate_cpu:celery_app worker --loglevel=INFO --concurrency 24 --cache_implementation file --include_architecture ControllableTalkNet --include_architecture SoVitsSvc3 --include_architecture SoVitsSvc4 --include_architecture SoVitsSvc5 --include_architecture Rvc --include_architecture StyleTTS2 &
              gunicorn --config=server_initialization.py --workers 24 --bind 0.0.0.0:6573 'wsgi:get_server(enable_model_management=True, update_model_lists_on_startup=True, enable_session_caches=False, migrate_models=True, cache_implementation=\"file\", architectures=[\"ControllableTalkNet\", \"SoVitsSvc3\", \"SoVitsSvc4\", \"SoVitsSvc5\", \"Rvc\", \"StyleTTS2\"])'
              "]
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s

  # This container provides a web service interface to so-vits-svc 3.0.
  so_vits_svc_3_server:
    depends_on:
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:so_vits_svc_3_server
    working_dir: /home/luna/hay_say/so_vits_svc_3
    volumes:
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    command: ["/bin/sh", "-c", "/home/luna/hay_say/.venvs/so_vits_svc_3_server/bin/python /home/luna/hay_say/so_vits_svc_3_server/main.py --cache_implementation file"]
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for so-vits-svc 3.0 if you wish.
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]

  # This container provides a web service interface to so-vits-svc 4.0.
  so_vits_svc_4_server:
    depends_on:
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:so_vits_svc_4_server
    working_dir: /home/luna/hay_say/so_vits_svc_4
    volumes:
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    command: ["/bin/sh", "-c", "/home/luna/hay_say/.venvs/so_vits_svc_4_server/bin/python /home/luna/hay_say/so_vits_svc_4_server/main.py --cache_implementation file"]
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for so-vits-svc 4.0 if you wish.
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]

  # This container provides a web service interface to so-vits-svc 5.0.
  so_vits_svc_5_server:
    depends_on:
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:so_vits_svc_5_server
    working_dir: /home/luna/hay_say/so_vits_svc_5
    volumes:
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    command: ["/bin/sh", "-c", "/home/luna/hay_say/.venvs/so_vits_svc_5_server/bin/python /home/luna/hay_say/so_vits_svc_5_server/main.py --cache_implementation file"]
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for so-vits-svc 5.0 if you wish.
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]

  # This container provides a web service interface to Retrieval-based Voice Conversion (RVC).
  rvc_server:
    depends_on:
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:rvc_server
    working_dir: /home/luna/hay_say/rvc
    volumes:
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    command: ["/bin/sh", "-c", "/home/luna/hay_say/.venvs/rvc_server/bin/python /home/luna/hay_say/rvc_server/main.py --cache_implementation file"]
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for RVC if you wish.
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]

  # This container provides a web service interface to Controllable TalkNet.
  controllable_talknet_server:
    depends_on:
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:controllable_talknet_server
    working_dir: /home/luna/hay_say/controllable_talknet
    volumes:
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    command: ["/bin/sh", "-c", "/home/luna/hay_say/.venvs/controllable_talknet_server/bin/python /home/luna/hay_say/controllable_talknet_server/main.py --cache_implementation file"]
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for Controllable TalkNet if you wish.
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]

# This container provides a web service interface to StyleTTS2.
  styletts_2_server:
    depends_on:
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:styletts_2_server
    working_dir: /home/luna/hay_say/styletts_2
    volumes:
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    command: ["/bin/sh", "-c", "/home/luna/hay_say/.venvs/styletts_2_server/bin/python /home/luna/hay_say/styletts_2_server/main.py --cache_implementation file"]
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for Controllable TalkNet if you wish.
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]

volumes:
  models:
    external: true
  audio_cache:
    external: true
  synthapp_models:
    external: true
