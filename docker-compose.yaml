# This is a static docker-compose file intended for the Alpha Release version of Hay Say.
# In the future, the docker-compose file will be dynamically generated according to user selections 
# in a launcher UI.

services:
  # Hay Say used to download character models via Docker by downloading special, data-only images called "model packs".
  # Model packs proved to be inefficient with disk space usage, so Hay Say was updated to allow users to download
  # individual characters directly from Mega, Google Drive, and Huggingface Hub instead. The models packs should still
  # work, however, and they are included below (but commented out) as a fallback in case there is an issue with
  # downloading models individually. See the Readme file for the list of characters included in each model pack.
  # Support for model packs will be removed in the future.

  # All current models for Controllable TalkNet
  # controllable_talknet_model_pack_0:
  #   image: hydrusbeta/hay_say:controllable_talknet_model_pack_0
  #   volumes:
  #     - controllable_talknet_model_pack_0:/root/hay_say/controllable_talknet_model_pack_0

  # Talking models for so-vits-svc 3.0
  # so_vits_svc_3_model_pack_0:
  #   image: hydrusbeta/hay_say:so_vits_svc_3_model_pack_0
  #   volumes:
  #     - so_vits_svc_3_model_pack_0:/root/hay_say/so_vits_svc_3_model_pack_0

  # Singing models for so-vits-svc 3.0.
  # so_vits_svc_3_model_pack_1:
  #   image: hydrusbeta/hay_say:so_vits_svc_3_model_pack_1
  #   volumes:
  #     - so_vits_svc_3_model_pack_1:/root/hay_say/so_vits_svc_3_model_pack_1

  # Talking models for so-vits-svc 4.0.
  # so_vits_svc_4_model_pack_0:
  #   image: hydrusbeta/hay_say:so_vits_svc_4_model_pack_0
  #   volumes:
  #     - so_vits_svc_4_model_pack_0:/root/hay_say/so_vits_svc_4_model_pack_0

  # Singing models for so-vits-svc 4.0.
  #  image: hydrusbeta/hay_say:so_vits_svc_4_model_pack_1
  #  volumes:
  #    - so_vits_svc_4_model_pack_1:/root/hay_say/so_vits_svc_4_model_pack_1

  # Multi-speaker so-vits-svc 4.0 model for Pinkie Pie's various emotions.
  # so_vits_svc_4_model_pack_2:
  #   image: hydrusbeta/hay_say:so_vits_svc_4_model_pack_2
  #   volumes:
  #     - so_vits_svc_4_model_pack_2:/root/hay_say/so_vits_svc_4_model_pack_2

  # Singing models of the Mane Six for so-vits-svc 5.0
  # so_vits_svc_5_model_pack_0:
  #   image: hydrusbeta/hay_say:so_vits_svc_5_model_pack_0
  #   volumes:
  #     - so_vits_svc_5_model_pack_0:/root/hay_say/so_vits_svc_5_model_pack_0

  # First group of pony models that were available for RVC
  # rvc_model_pack_0:
  #   image: hydrusbeta/hay_say:rvc_model_pack_0
  #   volumes:
  #     - rvc_model_pack_0:/root/hay_say/rvc_model_pack_0

  # Mane Six models for RVC
  # rvc_model_pack_1:
  #   image: hydrusbeta/hay_say:rvc_model_pack_1
  #   volumes:
  #     - rvc_model_pack_1:/root/hay_say/rvc_model_pack_1

  # The Redis container provides an in-memory data store that can be shared between applications.
  # This allows plotly to pass data to background workers.
  # In the future, the audio cache may also utilize redis instead of writing to files.
  redis:
    image: redis
    command: redis-server
    deploy:
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 30s

  # Mongo is a document-oriented database, perfect for storing python data dictionaries.
  mongo:
    image: mongo:jammy

  # This container runs the main UI
  hay_say_ui:
    depends_on:
      - redis
    image: hydrusbeta/hay_say:hay_say_ui
    ports:
      - 6573:6573
    working_dir: /root/hay_say/hay_say_ui
    volumes:
      # The container needs access to all the volumes so it can display the available characters in dropdown menus.
      - so_vits_svc_3_model_pack_0:/root/hay_say/so_vits_svc_3_model_pack_0
      - so_vits_svc_3_model_pack_1:/root/hay_say/so_vits_svc_3_model_pack_1
      - so_vits_svc_4_model_pack_0:/root/hay_say/so_vits_svc_4_model_pack_0
      - so_vits_svc_4_model_pack_1:/root/hay_say/so_vits_svc_4_model_pack_1
      - so_vits_svc_4_model_pack_2:/root/hay_say/so_vits_svc_4_model_pack_2
      - so_vits_svc_5_model_pack_0:/root/hay_say/so_vits_svc_5_model_pack_0
      - rvc_model_pack_0:/root/hay_say/rvc_model_pack_0
      - rvc_model_pack_1:/root/hay_say/rvc_model_pack_1
      - controllable_talknet_model_pack_0:/root/hay_say/controllable_talknet_model_pack_0
      - models:/root/hay_say/models
      - custom_models:/root/hay_say/custom_models
      - audio_cache:/root/hay_say/audio_cache
    # Override the CMD in the Docker file to enable model management, update model lists on startup, and automatically
    # migrate all models to the models folder. Also spin up 2 instances of celery, with 5 workers for downloading models
    # and a single worker for generating output.
    command: ["/bin/sh", "-c", "
              celery --workdir ~/hay_say/hay_say_ui/ -A celery_download:celery_app worker --loglevel=INFO --concurrency 5 --include_architecture ControllableTalkNet --include_architecture SoVitsSvc3 --include_architecture SoVitsSvc4 --include_architecture SoVitsSvc5 --include_architecture Rvc & 
              celery --workdir ~/hay_say/hay_say_ui -A celery_generate:celery_app worker --loglevel=INFO --concurrency 1 --cache_implementation file --include_architecture ControllableTalkNet --include_architecture SoVitsSvc3 --include_architecture SoVitsSvc4 --include_architecture SoVitsSvc5 --include_architecture Rvc &
              gunicorn --workers 1 --bind 0.0.0.0:6573 'wsgi:get_server(enable_model_management=True, update_model_lists_on_startup=True, migrate_models=True, cache_implementation=\"file\", architectures=[\"ControllableTalkNet\", \"SoVitsSvc3\", \"SoVitsSvc4\", \"SoVitsSvc5\", \"Rvc\"])'
              "]

  # This container provides a web service interface to so-vits-svc 3.0.
  so_vits_svc_3_server:
    depends_on:
      - redis
    image: hydrusbeta/hay_say:so_vits_svc_3_server
    working_dir: /root/hay_say/so_vits_svc_3
    volumes:
      - so_vits_svc_3_model_pack_0:/root/hay_say/so_vits_svc_3_model_pack_0
      - so_vits_svc_3_model_pack_1:/root/hay_say/so_vits_svc_3_model_pack_1
      - models:/root/hay_say/models
      - custom_models:/root/hay_say/custom_models
      - audio_cache:/root/hay_say/audio_cache
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for so-vits-svc 3.0 if you wish.
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

  # This container provides a web service interface to so-vits-svc 4.0.
  so_vits_svc_4_server:
    depends_on:
      - redis
    image: hydrusbeta/hay_say:so_vits_svc_4_server
    working_dir: /root/hay_say/so_vits_svc_4
    volumes:
      - so_vits_svc_4_model_pack_0:/root/hay_say/so_vits_svc_4_model_pack_0
      - so_vits_svc_4_model_pack_1:/root/hay_say/so_vits_svc_4_model_pack_1
      - so_vits_svc_4_model_pack_2:/root/hay_say/so_vits_svc_4_model_pack_2
      - models:/root/hay_say/models
      - custom_models:/root/hay_say/custom_models
      - audio_cache:/root/hay_say/audio_cache
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for so-vits-svc 4.0 if you wish.
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

  # This container provides a web service interface to so-vits-svc 5.0.
  so_vits_svc_5_server:
    depends_on:
      - redis
    image: hydrusbeta/hay_say:so_vits_svc_5_server
    working_dir: /root/hay_say/so_vits_svc_5
    volumes:
      - so_vits_svc_5_model_pack_0:/root/hay_say/so_vits_svc_5_model_pack_0
      - models:/root/hay_say/models
      - custom_models:/root/hay_say/custom_models
      - audio_cache:/root/hay_say/audio_cache
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for so-vits-svc 5.0 if you wish.
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

  # This container provides a web service interface to Retrieval-based Voice Conversion (RVC).
  rvc_server:
    depends_on:
      - redis
    image: hydrusbeta/hay_say:rvc_server
    ports:
      # Map port 7865 in case someone wants to see the original RVC UI. It's not really usable because it won't see the
      # model files or reference audio files.
      # Note: The original UI does not start up automatically. It can be manually started by executing the following command:
      # docker exec haysaydockercompose-rvc_server-1 /root/hay_say/.venvs/rvc/bin/python /root/hay_say/rvc/infer-web.py
      - 7865:7865
    working_dir: /root/hay_say/rvc
    volumes:
      - rvc_model_pack_0:/root/hay_say/rvc_model_pack_0
      - rvc_model_pack_1:/root/hay_say/rvc_model_pack_1
      - models:/root/hay_say/models
      - custom_models:/root/hay_say/custom_models
      - audio_cache:/root/hay_say/audio_cache
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for RVC if you wish.
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

  # This container provides a web service interface to Controllable TalkNet.
  controllable_talknet_server:
    depends_on:
      - redis
    image: hydrusbeta/hay_say:controllable_talknet_server
    ports:
      # Map port 8050 in case someone want to use the original Controllable TalkNet UI.
      # Note: The original UI does not start up automatically. It can be manually started by executing 2 commands:
      # docker exec haysaydockercompose-controllable_talknet_server-1 mkdir -p /talknet/is_docker
      # docker exec haysaydockercompose-controllable_talknet_server-1 /root/hay_say/.venvs/controllable_talknet/bin/python /root/hay_say/controllable_talknet/talknet_offline.py
      - 8050:8050
    working_dir: /root/hay_say/controllable_talknet
    volumes:
      - controllable_talknet_model_pack_0:/root/hay_say/controllable_talknet_model_pack_0
      - models:/root/hay_say/models
      - custom_models:/root/hay_say/custom_models
      - audio_cache:/root/hay_say/audio_cache
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for Controllable TalkNet if you wish.
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

volumes:
  so_vits_svc_3_model_pack_0:
  so_vits_svc_3_model_pack_1:
  so_vits_svc_4_model_pack_0:
  so_vits_svc_4_model_pack_1:
  so_vits_svc_4_model_pack_2:
  so_vits_svc_5_model_pack_0:
  rvc_model_pack_0:
  rvc_model_pack_1:
  controllable_talknet_model_pack_0:
  models:
    external: true
  custom_models:
    external: true
  audio_cache:
    external: true

