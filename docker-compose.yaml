# This is a static docker-compose file intended for local installations of Hay Say.
# In the future, a docker-compose file will be dynamically generated according to user selections in a launcher UI.

services:
  # Hay Say used to download character models via Docker by downloading special, data-only images called "model packs".
  # Model packs proved to be inefficient with disk space usage, so Hay Say was updated to allow users to download
  # individual characters directly from Mega, Google Drive, and Huggingface Hub instead. The models packs should still
  # work, however, and they are included below (but commented out) as a fallback in case there is an issue with
  # downloading models individually. See the Readme file for the list of characters included in each model pack.
  # Support for model packs will be removed in the future.

  # All current models for Controllable TalkNet
  # controllable_talknet_model_pack_0:
  #   image: hydrusbeta/hay_say:controllable_talknet_model_pack_0
  #   volumes:
  #     - controllable_talknet_model_pack_0:/home/luna/hay_say/controllable_talknet_model_pack_0

  # Talking models for so-vits-svc 3.0
  # so_vits_svc_3_model_pack_0:
  #   image: hydrusbeta/hay_say:so_vits_svc_3_model_pack_0
  #   volumes:
  #     - so_vits_svc_3_model_pack_0:/home/luna/hay_say/so_vits_svc_3_model_pack_0

  # Singing models for so-vits-svc 3.0.
  # so_vits_svc_3_model_pack_1:
  #   image: hydrusbeta/hay_say:so_vits_svc_3_model_pack_1
  #   volumes:
  #     - so_vits_svc_3_model_pack_1:/home/luna/hay_say/so_vits_svc_3_model_pack_1

  # Talking models for so-vits-svc 4.0.
  # so_vits_svc_4_model_pack_0:
  #   image: hydrusbeta/hay_say:so_vits_svc_4_model_pack_0
  #   volumes:
  #     - so_vits_svc_4_model_pack_0:/home/luna/hay_say/so_vits_svc_4_model_pack_0

  # Singing models for so-vits-svc 4.0.
  #  image: hydrusbeta/hay_say:so_vits_svc_4_model_pack_1
  #  volumes:
  #    - so_vits_svc_4_model_pack_1:/home/luna/hay_say/so_vits_svc_4_model_pack_1

  # Multi-speaker so-vits-svc 4.0 model for Pinkie Pie's various emotions.
  # so_vits_svc_4_model_pack_2:
  #   image: hydrusbeta/hay_say:so_vits_svc_4_model_pack_2
  #   volumes:
  #     - so_vits_svc_4_model_pack_2:/home/luna/hay_say/so_vits_svc_4_model_pack_2

  # Singing models of the Mane Six for so-vits-svc 5.0
  # so_vits_svc_5_model_pack_0:
  #   image: hydrusbeta/hay_say:so_vits_svc_5_model_pack_0
  #   volumes:
  #     - so_vits_svc_5_model_pack_0:/home/luna/hay_say/so_vits_svc_5_model_pack_0

  # First group of pony models that were available for RVC
  # rvc_model_pack_0:
  #   image: hydrusbeta/hay_say:rvc_model_pack_0
  #   volumes:
  #     - rvc_model_pack_0:/home/luna/hay_say/rvc_model_pack_0

  # Mane Six models for RVC
  # rvc_model_pack_1:
  #   image: hydrusbeta/hay_say:rvc_model_pack_1
  #   volumes:
  #     - rvc_model_pack_1:/home/luna/hay_say/rvc_model_pack_1

  # limited_user_migration is a service that runs on startup and ensures that all files in all 
  # Hay Say volumes are owned by the limited user (luna).
  limited_user_migration:
    image: hydrusbeta/hay_say:hay_say_ui
    user: root
    volumes:
      - so_vits_svc_3_model_pack_0:/home/luna/hay_say/so_vits_svc_3_model_pack_0
      - so_vits_svc_3_model_pack_1:/home/luna/hay_say/so_vits_svc_3_model_pack_1
      - so_vits_svc_4_model_pack_0:/home/luna/hay_say/so_vits_svc_4_model_pack_0
      - so_vits_svc_4_model_pack_1:/home/luna/hay_say/so_vits_svc_4_model_pack_1
      - so_vits_svc_4_model_pack_2:/home/luna/hay_say/so_vits_svc_4_model_pack_2
      - so_vits_svc_5_model_pack_0:/home/luna/hay_say/so_vits_svc_5_model_pack_0
      - rvc_model_pack_0:/home/luna/hay_say/rvc_model_pack_0
      - rvc_model_pack_1:/home/luna/hay_say/rvc_model_pack_1
      - controllable_talknet_model_pack_0:/home/luna/hay_say/controllable_talknet_model_pack_0
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    command: ["chown", "-R", "luna:luna", "/home/luna/hay_say/"]

  # The Redis container provides an in-memory data store that can be shared between applications.
  # This allows plotly to pass data to background workers.
  redis:
    image: redis
    command: redis-server
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      start_period: 15s
      start_interval: 1s
      # start_interval is not available in versions of Docker Engine earlier than 25. For backwards 
      # compatibility, set the interval property for now. Remove the line below sometime in the future, 
      # once everyone is on version 25+.
      interval: 1s

  # This container runs the main UI
  hay_say_ui:
    depends_on:
      limited_user_migration:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:hay_say_ui
    ports:
      - 6573:6573
    working_dir: /home/luna/hay_say/hay_say_ui
    volumes:
      # The container needs access to any model pack volumes so it can migrate their models to the models volume.
      - so_vits_svc_3_model_pack_0:/home/luna/hay_say/so_vits_svc_3_model_pack_0
      - so_vits_svc_3_model_pack_1:/home/luna/hay_say/so_vits_svc_3_model_pack_1
      - so_vits_svc_4_model_pack_0:/home/luna/hay_say/so_vits_svc_4_model_pack_0
      - so_vits_svc_4_model_pack_1:/home/luna/hay_say/so_vits_svc_4_model_pack_1
      - so_vits_svc_4_model_pack_2:/home/luna/hay_say/so_vits_svc_4_model_pack_2
      - so_vits_svc_5_model_pack_0:/home/luna/hay_say/so_vits_svc_5_model_pack_0
      - rvc_model_pack_0:/home/luna/hay_say/rvc_model_pack_0
      - rvc_model_pack_1:/home/luna/hay_say/rvc_model_pack_1
      - controllable_talknet_model_pack_0:/home/luna/hay_say/controllable_talknet_model_pack_0
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    # Override the CMD in the Docker file to enable model management, update model lists on startup, and automatically
    # migrate all models to the models folder. Also spin up 3 instances of celery (one for generating with CPU, one for
    # generating with GPU and one for downloading models), with 5 workers for downloading models and a single worker 
    # each for generating output with GPU and CPU.
    command: ["/bin/sh", "-c", "
              celery --workdir ~/hay_say/hay_say_ui/ -A celery_download:celery_app worker --loglevel=INFO --concurrency 5 --include_architecture ControllableTalkNet --include_architecture SoVitsSvc3 --include_architecture SoVitsSvc4 --include_architecture SoVitsSvc5 --include_architecture Rvc & 
              celery --workdir ~/hay_say/hay_say_ui/ -A celery_generate_gpu:celery_app worker --loglevel=INFO --concurrency 1 --cache_implementation file --include_architecture ControllableTalkNet --include_architecture SoVitsSvc3 --include_architecture SoVitsSvc4 --include_architecture SoVitsSvc5 --include_architecture Rvc &
              celery --workdir ~/hay_say/hay_say_ui/ -A celery_generate_cpu:celery_app worker --loglevel=INFO --concurrency 1 --cache_implementation file --include_architecture ControllableTalkNet --include_architecture SoVitsSvc3 --include_architecture SoVitsSvc4 --include_architecture SoVitsSvc5 --include_architecture Rvc &
              gunicorn --config=server_initialization.py --workers 6 --bind 0.0.0.0:6573 'wsgi:get_server(enable_model_management=True, update_model_lists_on_startup=True, enable_session_caches=False, migrate_models=True, cache_implementation=\"file\", architectures=[\"ControllableTalkNet\", \"SoVitsSvc3\", \"SoVitsSvc4\", \"SoVitsSvc5\", \"Rvc\"])'
              "]
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s

  # This container provides a web service interface to so-vits-svc 3.0.
  so_vits_svc_3_server:
    depends_on:
      limited_user_migration:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:so_vits_svc_3_server
    working_dir: /home/luna/hay_say/so_vits_svc_3
    volumes:
      - so_vits_svc_3_model_pack_0:/home/luna/hay_say/so_vits_svc_3_model_pack_0
      - so_vits_svc_3_model_pack_1:/home/luna/hay_say/so_vits_svc_3_model_pack_1
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    command: ["/bin/sh", "-c", "/home/luna/hay_say/.venvs/so_vits_svc_3_server/bin/python /home/luna/hay_say/so_vits_svc_3_server/main.py --cache_implementation file"]
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for so-vits-svc 3.0 if you wish.
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]

  # This container provides a web service interface to so-vits-svc 4.0.
  so_vits_svc_4_server:
    depends_on:
      limited_user_migration:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:so_vits_svc_4_server
    working_dir: /home/luna/hay_say/so_vits_svc_4
    volumes:
      - so_vits_svc_4_model_pack_0:/home/luna/hay_say/so_vits_svc_4_model_pack_0
      - so_vits_svc_4_model_pack_1:/home/luna/hay_say/so_vits_svc_4_model_pack_1
      - so_vits_svc_4_model_pack_2:/home/luna/hay_say/so_vits_svc_4_model_pack_2
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    command: ["/bin/sh", "-c", "/home/luna/hay_say/.venvs/so_vits_svc_4_server/bin/python /home/luna/hay_say/so_vits_svc_4_server/main.py --cache_implementation file"]
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for so-vits-svc 4.0 if you wish.
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]

  # This container provides a web service interface to so-vits-svc 5.0.
  so_vits_svc_5_server:
    depends_on:
      limited_user_migration:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:so_vits_svc_5_server
    working_dir: /home/luna/hay_say/so_vits_svc_5
    volumes:
      - so_vits_svc_5_model_pack_0:/home/luna/hay_say/so_vits_svc_5_model_pack_0
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    command: ["/bin/sh", "-c", "/home/luna/hay_say/.venvs/so_vits_svc_5_server/bin/python /home/luna/hay_say/so_vits_svc_5_server/main.py --cache_implementation file"]
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for so-vits-svc 5.0 if you wish.
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]

  # This container provides a web service interface to Retrieval-based Voice Conversion (RVC).
  rvc_server:
    depends_on:
      limited_user_migration:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:rvc_server
    ports:
      # Map port 7865 in case someone wants to see the original RVC UI. It's not really usable because it won't see the
      # model files or reference audio files.
      # Note: The original UI does not start up automatically. It can be manually started by executing the following command:
      # docker exec hay_say_ui-rvc_server-1 /home/luna/hay_say/.venvs/rvc/bin/python /home/luna/hay_say/rvc/infer-web.py
      - 7865:7865
    working_dir: /home/luna/hay_say/rvc
    volumes:
      - rvc_model_pack_0:/home/luna/hay_say/rvc_model_pack_0
      - rvc_model_pack_1:/home/luna/hay_say/rvc_model_pack_1
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    command: ["/bin/sh", "-c", "/home/luna/hay_say/.venvs/rvc_server/bin/python /home/luna/hay_say/rvc_server/main.py --cache_implementation file"]
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for RVC if you wish.
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]

  # This container provides a web service interface to Controllable TalkNet.
  controllable_talknet_server:
    depends_on:
      limited_user_migration:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    image: hydrusbeta/hay_say:controllable_talknet_server
    ports:
      # Map port 8050 in case someone want to use the original Controllable TalkNet UI.
      # Note: The original UI does not start up automatically. It can be manually started by executing 2 commands:
      # docker exec hay_say_ui-controllable_talknet_server-1 mkdir -p /talknet/is_docker
      # docker exec hay_say_ui-controllable_talknet_server-1 /home/luna/hay_say/.venvs/controllable_talknet/bin/python /home/luna/hay_say/controllable_talknet/talknet_offline.py
      - 8050:8050
    working_dir: /home/luna/hay_say/controllable_talknet
    volumes:
      - controllable_talknet_model_pack_0:/home/luna/hay_say/controllable_talknet_model_pack_0
      - models:/home/luna/hay_say/models
      - audio_cache:/home/luna/hay_say/audio_cache
    command: ["/bin/sh", "-c", "/home/luna/hay_say/.venvs/controllable_talknet_server/bin/python /home/luna/hay_say/controllable_talknet_server/main.py --cache_implementation file"]
    # GPU integration is disabled by default to prevent an error on machines that do not have a Cuda-capable GPU.
    # Uncomment the lines below to enable it for Controllable TalkNet if you wish.
    deploy:
      restart_policy:
        condition: on-failure
        window: 30s
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]

volumes:
  so_vits_svc_3_model_pack_0:
  so_vits_svc_3_model_pack_1:
  so_vits_svc_4_model_pack_0:
  so_vits_svc_4_model_pack_1:
  so_vits_svc_4_model_pack_2:
  so_vits_svc_5_model_pack_0:
  rvc_model_pack_0:
  rvc_model_pack_1:
  controllable_talknet_model_pack_0:
  models:
    external: true
  audio_cache:
    external: true

